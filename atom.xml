<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://www.luoboyu.com</id>
    <title>吴超武个人博客</title>
    <updated>2019-09-29T12:00:09.810Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://www.luoboyu.com"/>
    <link rel="self" href="https://www.luoboyu.com/atom.xml"/>
    <subtitle>业精于勤荒于嬉，行成于思毁于随</subtitle>
    <logo>https://www.luoboyu.com/images/avatar.png</logo>
    <icon>https://www.luoboyu.com/favicon.ico</icon>
    <rights>All rights reserved 2019, 吴超武个人博客</rights>
    <entry>
        <title type="html"><![CDATA[kubernetes  常用的命令]]></title>
        <id>https://www.luoboyu.com/post/kubernetes-chang-yong-de-ming-ling</id>
        <link href="https://www.luoboyu.com/post/kubernetes-chang-yong-de-ming-ling">
        </link>
        <updated>2018-11-30T08:53:45.000Z</updated>
        <summary type="html"><![CDATA[<p>kubectl是Kubernetes集群的命令行工具，通过kubectl能够对集群本身进行管理，并能够在集群上进行容器化应用的安装部署<br>
kubelet：负责pod对应的容器创建、启停等任务，同时与master 节点密切协作，实现集群管理的基本功能<br>
kube-proxy:实现kubernetes Service 的通信与负载均衡机制的重要组件</p>
]]></summary>
        <content type="html"><![CDATA[<p>kubectl是Kubernetes集群的命令行工具，通过kubectl能够对集群本身进行管理，并能够在集群上进行容器化应用的安装部署<br>
kubelet：负责pod对应的容器创建、启停等任务，同时与master 节点密切协作，实现集群管理的基本功能<br>
kube-proxy:实现kubernetes Service 的通信与负载均衡机制的重要组件</p>
<!-- more -->
<h2 id="11-common-commands">1.1 Common Commands</h2>
<table>
<thead>
<tr>
<th>Name</th>
<th>Command</th>
</tr>
</thead>
<tbody>
<tr>
<td>Run curl test temporarily</td>
<td><code>kubectl run --rm mytest --image=yauritux/busybox-curl -it</code></td>
</tr>
<tr>
<td>Run wget test temporarily</td>
<td><code>kubectl run --rm mytest --image=busybox -it</code></td>
</tr>
<tr>
<td>Run nginx deployment with 2 replicas</td>
<td><code>kubectl run my-nginx --image=nginx --replicas=2 --port=80</code></td>
</tr>
<tr>
<td>Run nginx pod and expose it</td>
<td><code>kubectl run my-nginx --restart=Never --image=nginx --port=80 --expose</code></td>
</tr>
<tr>
<td>Run nginx deployment and expose it</td>
<td><code>kubectl run my-nginx --image=nginx --port=80 --expose</code></td>
</tr>
<tr>
<td>Set namespace preference</td>
<td><code>kubectl config set-context &lt;context_name&gt; --namespace=&lt;ns_name&gt;</code></td>
</tr>
<tr>
<td>List pods with nodes info</td>
<td><code>kubectl get pod -o wide</code></td>
</tr>
<tr>
<td>List everything</td>
<td><code>kubectl get all --all-namespaces</code></td>
</tr>
<tr>
<td>Get all services</td>
<td><code>kubectl get service --all-namespaces</code></td>
</tr>
<tr>
<td>Get all deployments</td>
<td><code>kubectl get deployments --all-namespaces</code></td>
</tr>
<tr>
<td>Show nodes with labels</td>
<td><code>kubectl get nodes --show-labels</code></td>
</tr>
<tr>
<td>Get resources with json output</td>
<td><code>kubectl get pods --all-namespaces -o json</code></td>
</tr>
<tr>
<td>Validate yaml file with dry run</td>
<td><code>kubectl create --dry-run --validate -f pod-dummy.yaml</code></td>
</tr>
<tr>
<td>Start a temporary pod for testing</td>
<td><code>kubectl run --rm -i -t --image=alpine test-$RANDOM -- sh</code></td>
</tr>
<tr>
<td>kubectl run shell command</td>
<td><code>kubectl exec -it mytest -- ls -l /etc/hosts</code></td>
</tr>
<tr>
<td>Get system conf via configmap</td>
<td><code>kubectl -n kube-system get cm kubeadm-config -o yaml</code></td>
</tr>
<tr>
<td>Get deployment yaml</td>
<td><code>kubectl -n denny-websites get deployment mysql -o yaml</code></td>
</tr>
<tr>
<td>Explain resource</td>
<td><code>kubectl explain pods</code>, <code>kubectl explain svc</code></td>
</tr>
<tr>
<td>Watch pods</td>
<td><code>kubectl get pods -n wordpress --watch</code></td>
</tr>
<tr>
<td>Query healthcheck endpoint</td>
<td><code>curl -L http://127.0.0.1:10250/healthz</code></td>
</tr>
<tr>
<td>Open a bash terminal in a pod</td>
<td><code>kubectl exec -it storage sh</code></td>
</tr>
<tr>
<td>Check pod environment variables</td>
<td><code>kubectl exec redis-master-ft9ex env</code></td>
</tr>
<tr>
<td>Enable kubectl shell autocompletion</td>
<td><code>echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt;~/.bashrc</code>, and reload</td>
</tr>
<tr>
<td>Use minikube dockerd in your laptop</td>
<td><code>eval $(minikube docker-env)</code>, No need to push docker hub any more</td>
</tr>
<tr>
<td>Kubectl apply a folder of yaml files</td>
<td><code>kubectl apply -R -f .</code></td>
</tr>
<tr>
<td>Get services sorted by name</td>
<td>kubectl get services –sort-by=.metadata.name</td>
</tr>
<tr>
<td>Get pods sorted by restart count</td>
<td>kubectl get pods –sort-by=’.status.containerStatuses[0].restartCount’</td>
</tr>
<tr>
<td>List pods and images</td>
<td>kubectl get pods -o=’custom-columns=PODS:.metadata.name,Images:.spec.containers[*].image’</td>
</tr>
<tr>
<td>List all container images</td>
<td><a href="https://github.com/dennyzhang/cheatsheet-kubernetes-A4/blob/master/list-all-images.sh#L14-L17">list-all-images.sh</a></td>
</tr>
<tr>
<td>kubeconfig skip tls verification</td>
<td><a href="https://github.com/dennyzhang/cheatsheet-kubernetes-A4/blob/master/skip-tls-verify.md">skip-tls-verify.md</a></td>
</tr>
<tr>
<td><a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/">Ubuntu install kubectl</a></td>
<td>=”deb https://apt.kubernetes.io/ kubernetes-xenial main”=</td>
</tr>
<tr>
<td>Reference</td>
<td><a href="https://github.com/kubernetes/kubernetes/tags">GitHub: kubernetes releases</a></td>
</tr>
<tr>
<td>Reference</td>
<td><a href="https://cheatsheet.dennyzhang.com/cheatsheet-minikube-A4">minikube cheatsheet</a>, <a href="https://cheatsheet.dennyzhang.com/cheatsheet-docker-A4">docker cheatsheet</a>, <a href="https://cheatsheet.dennyzhang.com/cheatsheet-openshift-A4">OpenShift CheatSheet</a></td>
</tr>
</tbody>
</table>
<h2 id="12-check-performance">1.2 Check Performance</h2>
<table>
<thead>
<tr>
<th>Name</th>
<th>Command</th>
</tr>
</thead>
<tbody>
<tr>
<td>Get node resource usage</td>
<td><code>kubectl top node</code></td>
</tr>
<tr>
<td>Get pod resource usage</td>
<td><code>kubectl top pod</code></td>
</tr>
<tr>
<td>Get resource usage for a given pod</td>
<td><code>kubectl top &lt;podname&gt; --containers</code></td>
</tr>
<tr>
<td>List resource utilization for all containers</td>
<td><code>kubectl top pod --all-namespaces --containers=true</code></td>
</tr>
</tbody>
</table>
<h2 id="13-resources-deletion">1.3 Resources Deletion</h2>
<table>
<thead>
<tr>
<th>Name</th>
<th>Command</th>
</tr>
</thead>
<tbody>
<tr>
<td>Delete pod</td>
<td><code>kubectl delete pod/&lt;pod-name&gt; -n &lt;my-namespace&gt;</code></td>
</tr>
<tr>
<td>Delete pod by force</td>
<td><code>kubectl delete pod/&lt;pod-name&gt; --grace-period=0 --force</code></td>
</tr>
<tr>
<td>Delete pods by labels</td>
<td><code>kubectl delete pod -l env=test</code></td>
</tr>
<tr>
<td>Delete deployments by labels</td>
<td><code>kubectl delete deployment -l app=wordpress</code></td>
</tr>
<tr>
<td>Delete all resources filtered by labels</td>
<td><code>kubectl delete pods,services -l name=myLabel</code></td>
</tr>
<tr>
<td>Delete resources under a namespace</td>
<td><code>kubectl -n my-ns delete po,svc --all</code></td>
</tr>
<tr>
<td>Delete persist volumes by labels</td>
<td><code>kubectl delete pvc -l app=wordpress</code></td>
</tr>
<tr>
<td>Delete state fulset only (not pods)</td>
<td><code>kubectl delete sts/&lt;stateful_set_name&gt; --cascade=false</code></td>
</tr>
</tbody>
</table>
<h2 id="14-log-conf-files">1.4 Log &amp; Conf Files</h2>
<table>
<thead>
<tr>
<th>Name</th>
<th>Comment</th>
</tr>
</thead>
<tbody>
<tr>
<td>Config folder</td>
<td><code>/etc/kubernetes/</code></td>
</tr>
<tr>
<td>Certificate files</td>
<td><code>/etc/kubernetes/pki/</code></td>
</tr>
<tr>
<td>Credentials to API server</td>
<td><code>/etc/kubernetes/kubelet.conf</code></td>
</tr>
<tr>
<td>Superuser credentials</td>
<td><code>/etc/kubernetes/admin.conf</code></td>
</tr>
<tr>
<td>kubectl config file</td>
<td><code>~/.kube/config</code></td>
</tr>
<tr>
<td>Kubernets working dir</td>
<td><code>/var/lib/kubelet/</code></td>
</tr>
<tr>
<td>Docker working dir</td>
<td><code>/var/lib/docker/</code>, <code>/var/log/containers/</code></td>
</tr>
<tr>
<td>Etcd working dir</td>
<td><code>/var/lib/etcd/</code></td>
</tr>
<tr>
<td>Network cni</td>
<td><code>/etc/cni/net.d/</code></td>
</tr>
<tr>
<td>Log files</td>
<td><code>/var/log/pods/</code></td>
</tr>
<tr>
<td>log in worker node</td>
<td><code>/var/log/kubelet.log</code>, <code>/var/log/kube-proxy.log</code></td>
</tr>
<tr>
<td>log in master node</td>
<td><code>kube-apiserver.log</code>, <code>kube-scheduler.log</code>, <code>kube-controller-manager.log</code></td>
</tr>
<tr>
<td>Env</td>
<td><code>/etc/systemd/system/kubelet.service.d/10-kubeadm.conf</code></td>
</tr>
<tr>
<td>Env</td>
<td>export KUBECONFIG=/etc/kubernetes/admin.conf</td>
</tr>
</tbody>
</table>
<h2 id="15-pod">1.5 Pod</h2>
<table>
<thead>
<tr>
<th>Name</th>
<th>Command</th>
</tr>
</thead>
<tbody>
<tr>
<td>List all pods</td>
<td><code>kubectl get pods</code></td>
</tr>
<tr>
<td>List pods for all namespace</td>
<td><code>kubectl get pods -all-namespaces</code></td>
</tr>
<tr>
<td>List all critical pods</td>
<td><code>kubectl get -n kube-system pods -a</code></td>
</tr>
<tr>
<td>List pods with more info</td>
<td><code>kubectl get pod -o wide</code>, <code>kubectl get pod/&lt;pod-name&gt; -o yaml</code></td>
</tr>
<tr>
<td>Get pod info</td>
<td><code>kubectl describe pod/srv-mysql-server</code></td>
</tr>
<tr>
<td>List all pods with labels</td>
<td><code>kubectl get pods --show-labels</code></td>
</tr>
<tr>
<td><a href="https://github.com/kubernetes/kubernetes/issues/49387">List all unhealthy pods</a></td>
<td>kubectl get pods –field-selector=status.phase!=Running –all-namespaces</td>
</tr>
<tr>
<td>List running pods</td>
<td>kubectl get pods –field-selector=status.phase=Running</td>
</tr>
<tr>
<td>Get Pod initContainer status</td>
<td><code>kubectl get pod --template '{{.status.initContainerStatuses}}' &lt;pod-name&gt;</code></td>
</tr>
<tr>
<td>kubectl run command</td>
<td>kubectl exec -it -n “<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>n</mi><mi>s</mi><mi mathvariant="normal">”</mi><mi mathvariant="normal">“</mi></mrow><annotation encoding="application/x-tex">ns” “</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">n</span><span class="mord mathdefault">s</span><span class="mord">”</span><span class="mord">“</span></span></span></span>podname” – sh -c “echo $msg &gt;&gt;/dev/err.log”</td>
</tr>
<tr>
<td>Watch pods</td>
<td><code>kubectl get pods -n wordpress --watch</code></td>
</tr>
<tr>
<td>Get pod by selector</td>
<td>kubectl get pods –selector=”app=syslog” -o jsonpath=’{.items[*].metadata.name}’</td>
</tr>
<tr>
<td>List pods and images</td>
<td>kubectl get pods -o=’custom-columns=PODS:.metadata.name,Images:.spec.containers[*].image’</td>
</tr>
<tr>
<td>List pods and containers</td>
<td>-o=’custom-columns=PODS:.metadata.name,CONTAINERS:.spec.containers[*].name’</td>
</tr>
<tr>
<td>Reference</td>
<td><a href="https://cheatsheet.dennyzhang.com/kubernetes-yaml-templates">Link: kubernetes yaml templates</a></td>
</tr>
</tbody>
</table>
<h2 id="16-label-annontation">1.6 Label &amp; Annontation</h2>
<table>
<thead>
<tr>
<th>Name</th>
<th>Command</th>
</tr>
</thead>
<tbody>
<tr>
<td>Filter pods by label</td>
<td><code>kubectl get pods -l owner=denny</code></td>
</tr>
<tr>
<td>Manually add label to a pod</td>
<td><code>kubectl label pods dummy-input owner=denny</code></td>
</tr>
<tr>
<td>Remove label</td>
<td><code>kubectl label pods dummy-input owner-</code></td>
</tr>
<tr>
<td>Manually add annonation to a pod</td>
<td><code>kubectl annotate pods dummy-input my-url=https://dennyzhang.com</code></td>
</tr>
</tbody>
</table>
<h2 id="17-deployment-scale">1.7 Deployment &amp; Scale</h2>
<table>
<thead>
<tr>
<th>Name</th>
<th>Command</th>
</tr>
</thead>
<tbody>
<tr>
<td>Scale out</td>
<td><code>kubectl scale --replicas=3 deployment/nginx-app</code></td>
</tr>
<tr>
<td>online rolling upgrade</td>
<td><code>kubectl rollout app-v1 app-v2 --image=img:v2</code></td>
</tr>
<tr>
<td>Roll backup</td>
<td><code>kubectl rollout app-v1 app-v2 --rollback</code></td>
</tr>
<tr>
<td>List rollout</td>
<td><code>kubectl get rs</code></td>
</tr>
<tr>
<td>Check update status</td>
<td><code>kubectl rollout status deployment/nginx-app</code></td>
</tr>
<tr>
<td>Check update history</td>
<td><code>kubectl rollout history deployment/nginx-app</code></td>
</tr>
<tr>
<td>Pause/Resume</td>
<td><code>kubectl rollout pause deployment/nginx-deployment</code>, <code>resume</code></td>
</tr>
<tr>
<td>Rollback to previous version</td>
<td><code>kubectl rollout undo deployment/nginx-deployment</code></td>
</tr>
<tr>
<td>Reference</td>
<td><a href="https://cheatsheet.dennyzhang.com/kubernetes-yaml-templates">Link: kubernetes yaml templates</a>, <a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#pausing-and-resuming-a-deployment">Link: Pausing and Resuming a Deployment</a></td>
</tr>
</tbody>
</table>
<h2 id="18-quota-limits-resource">1.8 Quota &amp; Limits &amp; Resource</h2>
<table>
<thead>
<tr>
<th>Name</th>
<th>Command</th>
</tr>
</thead>
<tbody>
<tr>
<td>List Resource Quota</td>
<td><code>kubectl get resourcequota</code></td>
</tr>
<tr>
<td>List Limit Range</td>
<td><code>kubectl get limitrange</code></td>
</tr>
<tr>
<td>Customize resource definition</td>
<td><code>kubectl set resources deployment nginx -c=nginx --limits=cpu=200m</code></td>
</tr>
<tr>
<td>Customize resource definition</td>
<td><code>kubectl set resources deployment nginx -c=nginx --limits=memory=512Mi</code></td>
</tr>
<tr>
<td>Reference</td>
<td><a href="https://cheatsheet.dennyzhang.com/kubernetes-yaml-templates">Link: kubernetes yaml templates</a></td>
</tr>
</tbody>
</table>
<h2 id="19-service">1.9 Service</h2>
<table>
<thead>
<tr>
<th>Name</th>
<th>Command</th>
</tr>
</thead>
<tbody>
<tr>
<td>List all services</td>
<td><code>kubectl get services</code></td>
</tr>
<tr>
<td>List service endpoints</td>
<td><code>kubectl get endpoints</code></td>
</tr>
<tr>
<td>Get service detail</td>
<td><code>kubectl get service nginx-service -o yaml</code></td>
</tr>
<tr>
<td>Get service cluster ip</td>
<td>kubectl get service nginx-service -o go-template=’{{.spec.clusterIP}}’</td>
</tr>
<tr>
<td>Get service cluster port</td>
<td>kubectl get service nginx-service -o go-template=’{{(index .spec.ports 0).port}}’</td>
</tr>
<tr>
<td>Expose deployment as lb service</td>
<td><code>kubectl expose deployment/my-app --type=LoadBalancer --name=my-service</code></td>
</tr>
<tr>
<td>Expose service as lb service</td>
<td><code>kubectl expose service/wordpress-1-svc --type=LoadBalancer --name=ns1</code></td>
</tr>
<tr>
<td>Reference</td>
<td><a href="https://cheatsheet.dennyzhang.com/kubernetes-yaml-templates">Link: kubernetes yaml templates</a></td>
</tr>
</tbody>
</table>
<h2 id="110-secrets">1.10 Secrets</h2>
<table>
<thead>
<tr>
<th>Name</th>
<th>Command</th>
</tr>
</thead>
<tbody>
<tr>
<td>List secrets</td>
<td><code>kubectl get secrets --all-namespaces</code></td>
</tr>
<tr>
<td>Generate secret</td>
<td><code>echo -n 'mypasswd'=, then redirect to =base64 --decode</code></td>
</tr>
<tr>
<td>Get secret</td>
<td><code>kubectl get secret denny-cluster-kubeconfig</code></td>
</tr>
<tr>
<td>Get a specific field of a secret</td>
<td>kubectl get secret denny-cluster-kubeconfig -o jsonpath=”{.data.value}”</td>
</tr>
<tr>
<td>Create secret from cfg file</td>
<td>kubectl create secret generic db-user-pass –from-file=./username.txt</td>
</tr>
<tr>
<td>Reference</td>
<td><a href="https://cheatsheet.dennyzhang.com/kubernetes-yaml-templates">Link: kubernetes yaml templates</a>, <a href="https://kubernetes.io/docs/concepts/configuration/secret/">Link: Secrets</a></td>
</tr>
</tbody>
</table>
<h2 id="111-statefulset">1.11 StatefulSet</h2>
<table>
<thead>
<tr>
<th>Name</th>
<th>Command</th>
</tr>
</thead>
<tbody>
<tr>
<td>List statefulset</td>
<td><code>kubectl get sts</code></td>
</tr>
<tr>
<td>Delete statefulset only (not pods)</td>
<td><code>kubectl delete sts/&lt;stateful_set_name&gt; --cascade=false</code></td>
</tr>
<tr>
<td>Scale statefulset</td>
<td><code>kubectl scale sts/&lt;stateful_set_name&gt; --replicas=5</code></td>
</tr>
<tr>
<td>Reference</td>
<td><a href="https://cheatsheet.dennyzhang.com/kubernetes-yaml-templates">Link: kubernetes yaml templates</a></td>
</tr>
</tbody>
</table>
<h2 id="112-volumes-volume-claims">1.12 Volumes &amp; Volume Claims</h2>
<table>
<thead>
<tr>
<th>Name</th>
<th>Command</th>
</tr>
</thead>
<tbody>
<tr>
<td>List storage class</td>
<td><code>kubectl get storageclass</code></td>
</tr>
<tr>
<td>Check the mounted volumes</td>
<td><code>kubectl exec storage ls /data</code></td>
</tr>
<tr>
<td>Check persist volume</td>
<td><code>kubectl describe pv/pv0001</code></td>
</tr>
<tr>
<td>Copy local file to pod</td>
<td><code>kubectl cp /tmp/my &lt;some-namespace&gt;/&lt;some-pod&gt;:/tmp/server</code></td>
</tr>
<tr>
<td>Copy pod file to local</td>
<td><code>kubectl cp &lt;some-namespace&gt;/&lt;some-pod&gt;:/tmp/server /tmp/my</code></td>
</tr>
<tr>
<td>Reference</td>
<td><a href="https://cheatsheet.dennyzhang.com/kubernetes-yaml-templates">Link: kubernetes yaml templates</a></td>
</tr>
</tbody>
</table>
<h2 id="113-events-metrics">1.13 Events &amp; Metrics</h2>
<table>
<thead>
<tr>
<th>Name</th>
<th>Command</th>
</tr>
</thead>
<tbody>
<tr>
<td>View all events</td>
<td><code>kubectl get events --all-namespaces</code></td>
</tr>
<tr>
<td>List Events sorted by timestamp</td>
<td>kubectl get events –sort-by=.metadata.creationTimestamp</td>
</tr>
</tbody>
</table>
<h2 id="114-node-maintenance">1.14 Node Maintenance</h2>
<table>
<thead>
<tr>
<th>Name</th>
<th>Command</th>
</tr>
</thead>
<tbody>
<tr>
<td>Mark node as unschedulable</td>
<td><code>kubectl cordon $NDOE_NAME</code></td>
</tr>
<tr>
<td>Mark node as schedulable</td>
<td><code>kubectl uncordon $NDOE_NAME</code></td>
</tr>
<tr>
<td>Drain node in preparation for maintenance</td>
<td><code>kubectl drain $NODE_NAME</code></td>
</tr>
</tbody>
</table>
<h2 id="115-namespace-security">1.15 Namespace &amp; Security</h2>
<table>
<thead>
<tr>
<th>Name</th>
<th>Command</th>
</tr>
</thead>
<tbody>
<tr>
<td>List authenticated contexts</td>
<td><code>kubectl config get-contexts</code>, <code>~/.kube/config</code></td>
</tr>
<tr>
<td>Set namespace preference</td>
<td><code>kubectl config set-context &lt;context_name&gt; --namespace=&lt;ns_name&gt;</code></td>
</tr>
<tr>
<td>Load context from config file</td>
<td><code>kubectl get cs --kubeconfig kube_config.yml</code></td>
</tr>
<tr>
<td>Switch context</td>
<td><code>kubectl config use-context &lt;cluster-name&gt;</code></td>
</tr>
<tr>
<td>Delete the specified context</td>
<td><code>kubectl config delete-context &lt;cluster-name&gt;</code></td>
</tr>
<tr>
<td>List all namespaces defined</td>
<td><code>kubectl get namespaces</code></td>
</tr>
<tr>
<td>List certificates</td>
<td><code>kubectl get csr</code></td>
</tr>
<tr>
<td>Reference</td>
<td><a href="https://cheatsheet.dennyzhang.com/kubernetes-yaml-templates">Link: kubernetes yaml templates</a></td>
</tr>
</tbody>
</table>
<h2 id="116-network">1.16 Network</h2>
<table>
<thead>
<tr>
<th>Name</th>
<th>Command</th>
</tr>
</thead>
<tbody>
<tr>
<td>Temporarily add a port-forwarding</td>
<td><code>kubectl port-forward redis-134 6379:6379</code></td>
</tr>
<tr>
<td>Add port-forwaring for deployment</td>
<td><code>kubectl port-forward deployment/redis-master 6379:6379</code></td>
</tr>
<tr>
<td>Add port-forwaring for replicaset</td>
<td><code>kubectl port-forward rs/redis-master 6379:6379</code></td>
</tr>
<tr>
<td>Add port-forwaring for service</td>
<td><code>kubectl port-forward svc/redis-master 6379:6379</code></td>
</tr>
<tr>
<td>Get network policy</td>
<td><code>kubectl get NetworkPolicy</code></td>
</tr>
</tbody>
</table>
<h2 id="117-patch">1.17 Patch</h2>
<table>
<thead>
<tr>
<th>Name</th>
<th>Summary</th>
</tr>
</thead>
<tbody>
<tr>
<td>Patch service to loadbalancer</td>
<td>=kubectl patch svc $svc_name -p ‘{“spec”: {“type”: “LoadBalancer”}}’=</td>
</tr>
</tbody>
</table>
<h2 id="118-extenstions">1.18 Extenstions</h2>
<table>
<thead>
<tr>
<th>Name</th>
<th>Summary</th>
</tr>
</thead>
<tbody>
<tr>
<td>List api group</td>
<td><code>kubectl api-versions</code></td>
</tr>
<tr>
<td>List all CRD</td>
<td><code>kubectl get crd</code></td>
</tr>
<tr>
<td>List storageclass</td>
<td><code>kubectl get storageclass</code></td>
</tr>
<tr>
<td>List all supported resources</td>
<td><code>kubectl api-resources</code></td>
</tr>
</tbody>
</table>
<h3 id="1191-services-on-master-nodes">1.19.1 Services on Master Nodes</h3>
<table>
<thead>
<tr>
<th>Name</th>
<th>Summary</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/kubernetes/kubernetes/tree/master/cmd/kube-apiserver">kube-apiserver</a></td>
<td>exposes the Kubernetes API from master nodes</td>
</tr>
<tr>
<td><a href="https://coreos.com/etcd/">etcd</a></td>
<td>reliable data store for all k8s cluster data</td>
</tr>
<tr>
<td><a href="https://github.com/kubernetes/kubernetes/tree/master/cmd/kube-scheduler">kube-scheduler</a></td>
<td>schedule pods to run on selected nodes</td>
</tr>
<tr>
<td><a href="https://github.com/kubernetes/kubernetes/tree/master/cmd/kube-controller-manager">kube-controller-manager</a></td>
<td>node controller, replication controller, endpoints controller, and service account &amp; token controllers</td>
</tr>
</tbody>
</table>
<h3 id="1192-services-on-worker-nodes">1.19.2 Services on Worker Nodes</h3>
<table>
<thead>
<tr>
<th>Name</th>
<th>Summary</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/kubernetes/kubernetes/tree/master/cmd/kubelet">kubelet</a></td>
<td>makes sure that containers are running in a pod</td>
</tr>
<tr>
<td><a href="https://github.com/kubernetes/kubernetes/tree/master/cmd/kube-proxy">kube-proxy</a></td>
<td>perform connection forwarding</td>
</tr>
<tr>
<td><a href="https://github.com/docker/engine">Container Runtime</a></td>
<td>Kubernetes supported runtimes: Docker, rkt, runc and any <a href="https://github.com/opencontainers/runtime-spec">OCI runtime-spec</a> implementation.</td>
</tr>
</tbody>
</table>
<h3 id="1193-addons-pods-and-services-that-implement-cluster-features">1.19.3 Addons: pods and services that implement cluster features</h3>
<table>
<thead>
<tr>
<th>Name</th>
<th>Summary</th>
</tr>
</thead>
<tbody>
<tr>
<td>DNS</td>
<td>serves DNS records for Kubernetes services</td>
</tr>
<tr>
<td>Web UI</td>
<td>a general purpose, web-based UI for Kubernetes clusters</td>
</tr>
<tr>
<td>Container Resource Monitoring</td>
<td>collect, store and serve container metrics</td>
</tr>
<tr>
<td>Cluster-level Logging</td>
<td>save container logs to a central log store with search/browsing interface</td>
</tr>
</tbody>
</table>
<h3 id="1194-tools">1.19.4 Tools</h3>
<table>
<thead>
<tr>
<th>Name</th>
<th>Summary</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/kubernetes/kubernetes/tree/master/cmd/kubectl">kubectl</a></td>
<td>the command line util to talk to k8s cluster</td>
</tr>
<tr>
<td><a href="https://github.com/kubernetes/kubernetes/tree/master/cmd/kubeadm">kubeadm</a></td>
<td>the command to bootstrap the cluster</td>
</tr>
<tr>
<td><a href="https://kubernetes.io/docs/reference/setup-tools/kubefed/kubefed/">kubefed</a></td>
<td>the command line to control a Kubernetes Cluster Federation</td>
</tr>
<tr>
<td>Kubernetes Components</td>
<td><a href="https://kubernetes.io/docs/concepts/overview/components/">Link: Kubernetes Components</a></td>
</tr>
</tbody>
</table>
<h2 id="120-more-resources">1.20 More Resources</h2>
<p>https://kubernetes.io/docs/reference/kubectl/cheatsheet/</p>
<p>https://codefresh.io/kubernetes-guides/kubernetes-cheat-sheet/</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Minikube 使用]]></title>
        <id>https://www.luoboyu.com/post/hello-gridea</id>
        <link href="https://www.luoboyu.com/post/hello-gridea">
        </link>
        <updated>2018-10-10T16:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>背景介绍<br>
Minikube是什么？</p>
<p><a href="https://kubernetes.io/docs/tasks/tools/install-minikube/">Minikube</a>是一个能够在虚拟机中运行单节点Kubernetes集群的工具，它使得开发者可以在本地环境中进行开发和调试Kubernetes。推荐阿里封装的<a href="https://github.com/AliyunContainerService/minikube">minikube</a></p>
]]></summary>
        <content type="html"><![CDATA[<p>背景介绍<br>
Minikube是什么？</p>
<p><a href="https://kubernetes.io/docs/tasks/tools/install-minikube/">Minikube</a>是一个能够在虚拟机中运行单节点Kubernetes集群的工具，它使得开发者可以在本地环境中进行开发和调试Kubernetes。推荐阿里封装的<a href="https://github.com/AliyunContainerService/minikube">minikube</a></p>
<!-- more -->
<p>Kubernetes又是什么？</p>
<p>Kubernetes是一个用来自动部署、伸缩、和管理容器化应用的开源系统。<br>
容器又是什么？</p>
<p>容器指的是运用虚拟化技术将不同应用和其所需的运行环境进行隔离的进程，其中Docker是最著名的开源容器软件。</p>
<p><strong>容器又是什么？</strong></p>
<p>容器指的是运用虚拟化技术将不同应用和其所需的运行环境进行隔离的进程，其中<a href="https://www.docker.com/what-docker#/overview">Docker</a>是最著名的开源容器软件。</p>
<ul>
<li>我有几个项目使用的不同Node.js版本，开发调试需要进行切换很不方便。——容器的虚拟运行环境可以解决</li>
<li>每次部署都要重新安装依赖，而且不同环境依赖安装后可能出现问题。——打包成镜像，无需再安装依赖，秒级启动。</li>
<li>我想创建几个同样的进程做负载均衡/高可用。——用Kubernetes创建容器副本。</li>
<li>我希望我的进程在生产环境中挂掉或者被误杀之后自动重新启动。——用Kubernetes的自愈功能操作容器。</li>
<li>根据不同机器的资源使用情况来分配进程。——用Kubernetes来调度容器。<br>
…</li>
</ul>
<h2 id="hyper-vwindows8以上的系统默认已安装">Hyper-V（Windows8以上的系统默认已安装）</h2>
<p>首先<code>minikube start</code>会默认使用VirtualBox，但是我们用的是Hyper-V，所以需要加参数指定：</p>
<pre><code>minikube start --vm-driver=hyperv
</code></pre>
<p>还记得我们之前创建的虚拟网络交换机吗？这时候就需要用到它了。</p>
<pre><code>minikube start --vm-driver=hyperv --hyperv-virtual-switch=k8svswitch
</code></pre>
<p>默认不显示错误信息，为了方便排查启动中的问题，我们还是开启日志输出。</p>
<pre><code>minikube start --vm-driver=hyperv --hyperv-virtual-switch=k8svswitch --v=3 --alsologtostderr
</code></pre>
<p>默认需要2048Mb内存，如果不够我们需要<code>--memory 1024</code>指定一下更小的空间，当然我的机器10Gb的内存不可能不够，这个参数省略了~</p>
<p><strong>管理员模式打开命令行</strong>，执行上面那条<code>minikube start ...</code>开头的命令。</p>
<p>执行完成之后输入<code>kubectl cluster-info dump</code>，看到集群的大量详细信息表示安装成功~</p>
<p>如果按照以上步骤仍不成功，可以参考国外网友的一篇文章</p>
<p><a href="https://gibmirfred.de/2017/02/run-k8s-minikube-on-windows-10-with-hyper-v/">《Run k8s minikube on Windows 10 with Hyper-V》https://gibmirfred.de/2017/02/run-k8s-minikube-on-windows-10-with-hyper-v/</a></p>
<p>1.1 MINIKUBE BASIC<br>
Name	Command<br>
minikube lifecycle	minikube delete, minikube start, minikube status, Link: minikube<br>
Get minikube version	minikube version, Link: all minikube releases<br>
mac install minikube	brew cask install minikube, brew cask reinstall minikube<br>
Start minikube with different machine flavor	minikube start --memory 5120 --cpus=4<br>
Start minikube with a specific k8s version	minikube start --kubernetes-version v1.11.0<br>
Start minikube with more customizations	minikube start –kubernetes-version v1.11.0 –feature-gates=AdvancedAuditing=true<br>
SSH to minikube vm	minikube ssh, ssh -i ~/.minikube/machines/minikube/id_rsa docker@192.168.99.100<br>
Your local docker to use minikube dockerd	eval $(minikube docker-env), Then no need for docker push<br>
Minikube check latest version	minikube update-check<br>
Reference	Minikube CheatSheet, Kubernetes kind CheatSheet<br>
Reference	Kubectl CheatSheet, Kubernetes Yaml<br>
1.2 CHECK STATUS<br>
Name	Command<br>
Get minikube version	minikube version, Link: all minikube releases<br>
Get cluster info	kubectl cluster-info<br>
Get service info	minikube service <srv-name><br>
Get dashboard	minikube dashboard<br>
Get ip	minikube ip<br>
Get minikube log	minikube logs<br>
List addons	minikube addons list<br>
1.3 MINIKUBE FOLDERS<br>
Name	Command<br>
Mount host OS’s folder to minikube VM	minikube mount /host-mount-path:/vm-mount-path<br>
Folder of k8s.io/minikube-hostpath provisioner	/tmp/hostpath-provisioner, /tmp/hostpath_pv<br>
Mount host OS’s folder to minikube VM	minikube mount /host-mount-path:/vm-mount-path<br>
Critical minikube folder	/var/lib/localkube, /var/lib/docker, /data<br>
Check minikube config in your host OS desktop	~/.minikube/machines/minikube/config.json<br>
Minikube conf in local env	~/.minikube, ~/.kube<br>
1.4 MINIKUBE ADVANCED<br>
Name	Command<br>
Install addon after creating minikube env	minikube addons enable heapster, kubectl top node<br>
1.5 MINIKUBE CLI ONLINE HELP</p>
<blockquote>
<p>minikube version<br>
minikube version: v0.31.0</p>
</blockquote>
<blockquote>
<p>minikube --help<br>
Minikube is a CLI tool that provisions and manages single-node Kubernetes clusters optimized for development workflows.</p>
</blockquote>
<p>Usage:<br>
minikube [command]</p>
<p>Available Commands:<br>
addons         Modify minikube's kubernetes addons<br>
cache          Add or delete an image from the local cache.<br>
completion     Outputs minikube shell completion for the given shell (bash or zsh)<br>
config         Modify minikube config<br>
dashboard      Access the kubernetes dashboard running within the minikube cluster<br>
delete         Deletes a local kubernetes cluster<br>
docker-env     Sets up docker env variables; similar to '$(docker-machine env)'<br>
help           Help about any command<br>
ip             Retrieves the IP address of the running cluster<br>
logs           Gets the logs of the running instance, used for debugging minikube, not user code<br>
mount          Mounts the specified directory into minikube<br>
profile        Profile sets the current minikube profile<br>
service        Gets the kubernetes URL(s) for the specified service in your local cluster<br>
ssh            Log into or run a command on a machine with SSH; similar to 'docker-machine ssh'<br>
ssh-key        Retrieve the ssh identity key path of the specified cluster<br>
start          Starts a local kubernetes cluster<br>
status         Gets the status of a local kubernetes cluster<br>
stop           Stops a running local kubernetes cluster<br>
tunnel         tunnel makes services of type LoadBalancer accessible on localhost<br>
update-check   Print current and latest version number<br>
update-context Verify the IP address of the running cluster in kubeconfig.<br>
version        Print the version of minikube</p>
<p>Flags:<br>
--alsologtostderr                  log to standard error as well as files<br>
-b, --bootstrapper string              The name of the cluster bootstrapper that will set up the kubernetes cluster. (default &quot;kubeadm&quot;)<br>
-h, --help                             help for minikube<br>
--log_backtrace_at traceLocation   when logging hits line file:N, emit a stack trace (default :0)<br>
--log_dir string                   If non-empty, write log files in this directory<br>
--logtostderr                      log to standard error instead of files<br>
-p, --profile string                   The name of the minikube VM being used.<br>
This can be modified to allow for multiple minikube instances to be run independently (default &quot;minikube&quot;)<br>
--stderrthreshold severity         logs at or above this threshold go to stderr (default 2)<br>
-v, --v Level                          log level for V logs<br>
--vmodule moduleSpec               comma-separated list of pattern=N settings for file-filtered logging</p>
<p>Use &quot;minikube [command] --help&quot; for more information about a command.</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java微服务核心]]></title>
        <id>https://www.luoboyu.com/post/wei-fu-wu-he-xin</id>
        <link href="https://www.luoboyu.com/post/wei-fu-wu-he-xin">
        </link>
        <updated>2018-08-09T09:23:20.000Z</updated>
        <content type="html"><![CDATA[<ul>
<li>Distributed/versioned configuration【分布式以及版本化的配置】</li>
<li>Service registration and discovery【服务注册与发现】</li>
<li>Routing【路由】</li>
<li>Service-to-service calls【服务调用】</li>
<li>Load balancing【负载均衡】</li>
<li>Circuit Breakers【断路器】</li>
<li>Distributed messaging【分布式消息】</li>
</ul>
<h3 id="spring-cloud-netflix">spring-cloud （Netflix）</h3>
<ul>
<li>服务的注册与发现（Eureka）</li>
<li>服务消费者（rest+ribbon）</li>
<li>服务消费者（Feign）</li>
<li>断路器（Hystrix）</li>
<li>路由网关zuul,Spring Cloud Gateway</li>
<li>高可用的分布式配置中心(Spring Cloud Config)</li>
<li>消息总线(Spring Cloud Bus)</li>
<li>服务链路追踪(Spring Cloud Sleuth)</li>
<li>断路器监控(Hystrix Dashboard)</li>
<li>断路器聚合监控(Hystrix Turbine)</li>
<li>Resilience4j 代替 Hystrix</li>
<li>Hystrix Dashboard / Turbine替换为Micrometer + Monitoring System</li>
<li>Spring Cloud Loadbalancer 代替Ribbon</li>
<li>Spring Cloud Gateway 代替 Zuul</li>
<li>Spring Boot external config + Spring Cloud Config代替 Archaius 1</li>
</ul>
<p><strong>后期zuul hystrix，Ribbon将停止更新</strong></p>
<h3 id="apm应用程序性能监视和管理工具">APM（应用程序性能监视和管理）工具</h3>
<ul>
<li>Cat http://github.com/dianping/cat/</li>
<li>Zipkin https://zipkin.io/</li>
<li>Pinpoint https://github.com/naver/pinpoint/</li>
<li>Apache SkyWalking https://github.com/apacheincubator-skywalking</li>
</ul>
<h3 id="spring-cloud-alibaba">Spring Cloud Alibaba</h3>
<ul>
<li>Sentinel</li>
</ul>
<blockquote>
<p>把流量作为切入点，从流量控制、熔断降级、系统负载保等多个维度保护服务的稳定性。</p>
</blockquote>
<ul>
<li>Nacos</li>
</ul>
<blockquote>
<p>一个更易于构建云原生应用的动态服务发现、配置管理和服务理平台* * * 。</p>
</blockquote>
<ul>
<li>RocketMQ</li>
</ul>
<blockquote>
<p>一款开源的分布式消息系统，基于高可用分布式集群技术提供低延时的、高可靠的消息发布与订阅服务。</p>
</blockquote>
<ul>
<li>Seata</li>
</ul>
<blockquote>
<p>阿里巴巴开源产品，一个易于使用的高性能微服务分布式事务决方案。</p>
</blockquote>
<ul>
<li>Alibaba Cloud SchedulerX</li>
</ul>
<blockquote>
<p>阿里中间件团队开发的一款分布式任调度产品，提供秒级、精准、高可靠、高可用的定时（基于 Cron 表式）任务调度服务。</p>
</blockquote>
<h3 id="elk">ELK</h3>
<p>日志治理</p>
<blockquote>
<p>logback =&gt; kafka =&gt;logstash =&gt; elasticsearch =&gt; kibana</p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[JVM 工具]]></title>
        <id>https://www.luoboyu.com/post/jvm-gong-ju</id>
        <link href="https://www.luoboyu.com/post/jvm-gong-ju">
        </link>
        <updated>2016-04-04T11:51:23.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="jps">jps</h2>
<p>1、用来查看基于HotSpot JVM里面所有进程的具体状态, 包括进程ID，进程启动的路径等等，用来显示本地有权限的java进程，可以查看本地运行着几个java程序</p>
<p>2、命令格式</p>
<p><code>jps [ options ] [ hostid ]</code></p>
<p>3、常用参数说明<br>
-m 输出传递给main方法的参数，如果是内嵌的JVM则输出为null。<br>
-l 输出应用程序主类的完整包名，或者是应用程序JAR文件的完整路径。<br>
-v 输出传给JVM的参数。</p>
<h2 id="jstat">jstat</h2>
<p>jstat工具特别强大，有众多的可选项，详细查看堆内各个部分的使用量，以及加载类的数量。使用时，需加上查看进程的进程id，和所选参数。<br>
它主要是用来显示GC及PermGen相关的信息，否则其中即使你会使用jstat这个命令</p>
<p>2、命令格式<br>
<code>jstat [ generalOption | outputOptions vmid [interval[s|ms] [count]] ]</code></p>
<p>3、参数说明<br>
1）、generalOption：单个的常用的命令行选项，如-help, -options, 或 -version。<br>
2）、outputOptions：一个或多个输出选项，由单个的statOption选项组件，可以-t, -h, and -J选项配合使用。<br>
statOption：<br>
-class Option<br>
-compiler Option<br>
-gc Option<br>
-gccapacity Option<br>
-gccause Option<br>
-gcnew Option<br>
-gcnewcapacity Option<br>
-gcold Option<br>
-gcoldcapacity Option<br>
-gcpermcapacity Option<br>
-gcutil Option<br>
-printcompilation Option</p>
<p>选项了，因为他能够给我们展示大致的GC信息。<br>
Option：指的是vmid、显示间隔时间及间隔次数等<br>
vmid    — VM的进程号，即当前运行的java进程号<br>
interval– 间隔时间，单位为秒或者毫秒<br>
count   — 打印次数，如果缺省则打印无数次<br>
3）、jstat命令输出参数说明<br>
S0  — Heap上的 Survivor space 0 区已使用空间的百分比<br>
S0C：S0当前容量的大小<br>
S0U：S0已经使用的大小<br>
S1  — Heap上的 Survivor space 1 区已使用空间的百分比<br>
S1C：S1当前容量的大小<br>
S1U：S1已经使用的大小<br>
E   — Heap上的 Eden space 区已使用空间的百分比<br>
EC：Eden space当前容量的大小<br>
EU：Eden space已经使用的大小<br>
O   — Heap上的 Old space 区已使用空间的百分比<br>
OC：Old space当前容量的大小<br>
OU：Old space已经使用的大小<br>
P   — Perm space 区已使用空间的百分比<br>
OC：Perm space当前容量的大小<br>
OU：Perm space已经使用的大小<br>
YGC — 从应用程序启动到采样时发生 Young GC 的次数<br>
YGCT– 从应用程序启动到采样时 Young GC 所用的时间(单位秒)<br>
FGC — 从应用程序启动到采样时发生 Full GC 的次数<br>
FGCT– 从应用程序启动到采样时 Full GC 所用的时间(单位秒)<br>
GCT — 从应用程序启动到采样时用于垃圾回收的总时间(单位秒)，它的值等于YGC+FGC<br>
注：由于该工具参数过多，不再进行给出测试结果。</p>
<h2 id="jstack">jstack</h2>
<p>1、介绍<br>
jstack用于打印出给定的java进程ID或core file或远程调试服务的Java堆栈信息，如果是在64位机器上，需要指定选项&quot;-J-d64&quot;，Windows的jstack使用方式只支持以下的这种方式：<br>
jstack [-l] pid<br>
如果java程序崩溃生成core文件，jstack工具可以用来获得core文件的java stack和native stack的信息，从而可以轻松地知道java程序是如何崩溃和在程序何处发生问题。另外，jstack工具还可以附属到正在运行的java程序中，看到当时运行的java程序的java stack和native stack的信息, 如果现在运行的java程序呈现hung的状态，jstack是非常有用的。</p>
<p>2、命令格式<br>
jstack [ option ] pid<br>
jstack [ option ] executable core<br>
jstack [ option ] [server-id@]remote-hostname-or-IP</p>
<p>3、常用参数说明<br>
1)、options：<br>
executable Java executable from which the core dump was produced.<br>
(可能是产生core dump的java可执行程序)<br>
core 将被打印信息的core dump文件<br>
remote-hostname-or-IP 远程debug服务的主机名或ip<br>
server-id 唯一id,假如一台主机上多个远程debug服务<br>
2）、基本参数：<br>
-F当’jstack [-l] pid’没有相应的时候强制打印栈信息<br>
-l长列表. 打印关于锁的附加信息,例如属于java.util.concurrent的ownable synchronizers列表.<br>
-m打印java和native c/c++框架的所有栈信息.<br>
-h | -help打印帮助信息<br>
pid 需要被打印配置信息的java进程id,可以用jps查询.</p>
<h2 id="jmap">jmap</h2>
<p>1、介绍<br>
打印出某个java进程（使用pid）内存内的，所有对象的情况（如：产生那些对象，及其数量）。<br>
可以输出所有内存中对象的工具，甚至可以将VM 中的heap，以二进制输出成文本。使用方法 jmap -histo pid。如果连用SHELL jmap -histo pid&gt;a.log可以将其保存到文本中去，在一段时间后，使用文本对比工具，可以对比出GC回收了哪些对象。jmap -dump:format=b,file=outfile 3024可以将3024进程的内存heap输出出来到outfile文件里，再配合MAT（内存分析工具(Memory Analysis Tool）或与jhat (Java Heap Analysis Tool)一起使用，能够以图像的形式直观的展示当前内存是否有问题。<br>
64位机上使用需要使用如下方式：<br>
jmap -J-d64 -heap pid</p>
<p>2、命令格式<br>
SYNOPSIS<br>
jmap [ option ] pid<br>
jmap [ option ] executable core<br>
jmap [ option ] [server-id@]remote-hostname-or-IP</p>
<p>3、参数说明<br>
1)、options：<br>
executable Java executable from which the core dump was produced.<br>
(可能是产生core dump的java可执行程序)<br>
core 将被打印信息的core dump文件<br>
remote-hostname-or-IP 远程debug服务的主机名或ip<br>
server-id 唯一id,假如一台主机上多个远程debug服务<br>
2）、基本参数：<br>
-dump:[live,]format=b,file=<filename> 使用hprof二进制形式,输出jvm的heap内容到文件=. live子选项是可选的，假如指定live选项,那么只输出活的对象到文件.<br>
-finalizerinfo 打印正等候回收的对象的信息.<br>
-heap 打印heap的概要信息，GC使用的算法，heap的配置及wise heap的使用情况.<br>
-histo[:live] 打印每个class的实例数目,内存占用,类全名信息. VM的内部类名字开头会加上前缀”*”. 如果live子参数加上后,只统计活的对象数量.<br>
-permstat 打印classload和jvm heap长久层的信息. 包含每个classloader的名字,活泼性,地址,父classloader和加载的class数量. 另外,内部String的数量和占用内存数也会打印出来.<br>
-F 强迫.在pid没有相应的时候使用-dump或者-histo参数. 在这个模式下,live子参数无效.<br>
-h | -help 打印辅助信息<br>
-J 传递参数给jmap启动的jvm.<br>
pid 需要被打印配相信息的java进程id,创业与打工的区别 - 博文预览,可以用jps查问.<br>
注：平时该命令我是使用最多的。</p>
<h2 id="jinfo">jinfo</h2>
<p>jinfo可以输出并修改运行时的java 进程的opts。用处比较简单，用于输出JAVA系统参数及命令行参数。</p>
<h2 id="jconsole和jvisualvm">jconsole和jvisualvm</h2>
<p>jconsole:一个java GUI监视工具，可以以图表化的形式显示各种数据。并可通过远程连接监视远程的服务器VM。用java写的GUI程序，用来监控VM，并可监控远程的VM，非常易用，而且功能非常强。命令行里打 jconsole，选则进程就可以了。<br>
需要注意的就是在运行jconsole之前，必须要先设置环境变量DISPLAY，否则会报错误，Linux下设置环境变量如下：<br>
export DISPLAY=:0.0<br>
jvisualvm同jconsole都是一个基于图形化界面的、可以查看本地及远程的JAVA GUI监控工具，Jvisualvm同jconsole的使用方式一样，直接在命令行打入Jvisualvm即可启动，不过Jvisualvm相比，界面更美观一些，数据更实时。</p>
<p>##、Jhat<br>
jhat用于对JAVA heap进行离线分析的工具，他可以对不同虚拟机中导出的heap信息文件进行分析，如LINUX上导出的文件可以拿到WINDOWS上进行分析，可以查找诸如内存方面的问题，不过jhat和MAT比较起来，就没有MAT那么直观了，MAT是以图形界面的方式展现结果。</p>
]]></summary>
        <content type="html"><![CDATA[<h2 id="jps">jps</h2>
<p>1、用来查看基于HotSpot JVM里面所有进程的具体状态, 包括进程ID，进程启动的路径等等，用来显示本地有权限的java进程，可以查看本地运行着几个java程序</p>
<p>2、命令格式</p>
<p><code>jps [ options ] [ hostid ]</code></p>
<p>3、常用参数说明<br>
-m 输出传递给main方法的参数，如果是内嵌的JVM则输出为null。<br>
-l 输出应用程序主类的完整包名，或者是应用程序JAR文件的完整路径。<br>
-v 输出传给JVM的参数。</p>
<h2 id="jstat">jstat</h2>
<p>jstat工具特别强大，有众多的可选项，详细查看堆内各个部分的使用量，以及加载类的数量。使用时，需加上查看进程的进程id，和所选参数。<br>
它主要是用来显示GC及PermGen相关的信息，否则其中即使你会使用jstat这个命令</p>
<p>2、命令格式<br>
<code>jstat [ generalOption | outputOptions vmid [interval[s|ms] [count]] ]</code></p>
<p>3、参数说明<br>
1）、generalOption：单个的常用的命令行选项，如-help, -options, 或 -version。<br>
2）、outputOptions：一个或多个输出选项，由单个的statOption选项组件，可以-t, -h, and -J选项配合使用。<br>
statOption：<br>
-class Option<br>
-compiler Option<br>
-gc Option<br>
-gccapacity Option<br>
-gccause Option<br>
-gcnew Option<br>
-gcnewcapacity Option<br>
-gcold Option<br>
-gcoldcapacity Option<br>
-gcpermcapacity Option<br>
-gcutil Option<br>
-printcompilation Option</p>
<p>选项了，因为他能够给我们展示大致的GC信息。<br>
Option：指的是vmid、显示间隔时间及间隔次数等<br>
vmid    — VM的进程号，即当前运行的java进程号<br>
interval– 间隔时间，单位为秒或者毫秒<br>
count   — 打印次数，如果缺省则打印无数次<br>
3）、jstat命令输出参数说明<br>
S0  — Heap上的 Survivor space 0 区已使用空间的百分比<br>
S0C：S0当前容量的大小<br>
S0U：S0已经使用的大小<br>
S1  — Heap上的 Survivor space 1 区已使用空间的百分比<br>
S1C：S1当前容量的大小<br>
S1U：S1已经使用的大小<br>
E   — Heap上的 Eden space 区已使用空间的百分比<br>
EC：Eden space当前容量的大小<br>
EU：Eden space已经使用的大小<br>
O   — Heap上的 Old space 区已使用空间的百分比<br>
OC：Old space当前容量的大小<br>
OU：Old space已经使用的大小<br>
P   — Perm space 区已使用空间的百分比<br>
OC：Perm space当前容量的大小<br>
OU：Perm space已经使用的大小<br>
YGC — 从应用程序启动到采样时发生 Young GC 的次数<br>
YGCT– 从应用程序启动到采样时 Young GC 所用的时间(单位秒)<br>
FGC — 从应用程序启动到采样时发生 Full GC 的次数<br>
FGCT– 从应用程序启动到采样时 Full GC 所用的时间(单位秒)<br>
GCT — 从应用程序启动到采样时用于垃圾回收的总时间(单位秒)，它的值等于YGC+FGC<br>
注：由于该工具参数过多，不再进行给出测试结果。</p>
<h2 id="jstack">jstack</h2>
<p>1、介绍<br>
jstack用于打印出给定的java进程ID或core file或远程调试服务的Java堆栈信息，如果是在64位机器上，需要指定选项&quot;-J-d64&quot;，Windows的jstack使用方式只支持以下的这种方式：<br>
jstack [-l] pid<br>
如果java程序崩溃生成core文件，jstack工具可以用来获得core文件的java stack和native stack的信息，从而可以轻松地知道java程序是如何崩溃和在程序何处发生问题。另外，jstack工具还可以附属到正在运行的java程序中，看到当时运行的java程序的java stack和native stack的信息, 如果现在运行的java程序呈现hung的状态，jstack是非常有用的。</p>
<p>2、命令格式<br>
jstack [ option ] pid<br>
jstack [ option ] executable core<br>
jstack [ option ] [server-id@]remote-hostname-or-IP</p>
<p>3、常用参数说明<br>
1)、options：<br>
executable Java executable from which the core dump was produced.<br>
(可能是产生core dump的java可执行程序)<br>
core 将被打印信息的core dump文件<br>
remote-hostname-or-IP 远程debug服务的主机名或ip<br>
server-id 唯一id,假如一台主机上多个远程debug服务<br>
2）、基本参数：<br>
-F当’jstack [-l] pid’没有相应的时候强制打印栈信息<br>
-l长列表. 打印关于锁的附加信息,例如属于java.util.concurrent的ownable synchronizers列表.<br>
-m打印java和native c/c++框架的所有栈信息.<br>
-h | -help打印帮助信息<br>
pid 需要被打印配置信息的java进程id,可以用jps查询.</p>
<h2 id="jmap">jmap</h2>
<p>1、介绍<br>
打印出某个java进程（使用pid）内存内的，所有对象的情况（如：产生那些对象，及其数量）。<br>
可以输出所有内存中对象的工具，甚至可以将VM 中的heap，以二进制输出成文本。使用方法 jmap -histo pid。如果连用SHELL jmap -histo pid&gt;a.log可以将其保存到文本中去，在一段时间后，使用文本对比工具，可以对比出GC回收了哪些对象。jmap -dump:format=b,file=outfile 3024可以将3024进程的内存heap输出出来到outfile文件里，再配合MAT（内存分析工具(Memory Analysis Tool）或与jhat (Java Heap Analysis Tool)一起使用，能够以图像的形式直观的展示当前内存是否有问题。<br>
64位机上使用需要使用如下方式：<br>
jmap -J-d64 -heap pid</p>
<p>2、命令格式<br>
SYNOPSIS<br>
jmap [ option ] pid<br>
jmap [ option ] executable core<br>
jmap [ option ] [server-id@]remote-hostname-or-IP</p>
<p>3、参数说明<br>
1)、options：<br>
executable Java executable from which the core dump was produced.<br>
(可能是产生core dump的java可执行程序)<br>
core 将被打印信息的core dump文件<br>
remote-hostname-or-IP 远程debug服务的主机名或ip<br>
server-id 唯一id,假如一台主机上多个远程debug服务<br>
2）、基本参数：<br>
-dump:[live,]format=b,file=<filename> 使用hprof二进制形式,输出jvm的heap内容到文件=. live子选项是可选的，假如指定live选项,那么只输出活的对象到文件.<br>
-finalizerinfo 打印正等候回收的对象的信息.<br>
-heap 打印heap的概要信息，GC使用的算法，heap的配置及wise heap的使用情况.<br>
-histo[:live] 打印每个class的实例数目,内存占用,类全名信息. VM的内部类名字开头会加上前缀”*”. 如果live子参数加上后,只统计活的对象数量.<br>
-permstat 打印classload和jvm heap长久层的信息. 包含每个classloader的名字,活泼性,地址,父classloader和加载的class数量. 另外,内部String的数量和占用内存数也会打印出来.<br>
-F 强迫.在pid没有相应的时候使用-dump或者-histo参数. 在这个模式下,live子参数无效.<br>
-h | -help 打印辅助信息<br>
-J 传递参数给jmap启动的jvm.<br>
pid 需要被打印配相信息的java进程id,创业与打工的区别 - 博文预览,可以用jps查问.<br>
注：平时该命令我是使用最多的。</p>
<h2 id="jinfo">jinfo</h2>
<p>jinfo可以输出并修改运行时的java 进程的opts。用处比较简单，用于输出JAVA系统参数及命令行参数。</p>
<h2 id="jconsole和jvisualvm">jconsole和jvisualvm</h2>
<p>jconsole:一个java GUI监视工具，可以以图表化的形式显示各种数据。并可通过远程连接监视远程的服务器VM。用java写的GUI程序，用来监控VM，并可监控远程的VM，非常易用，而且功能非常强。命令行里打 jconsole，选则进程就可以了。<br>
需要注意的就是在运行jconsole之前，必须要先设置环境变量DISPLAY，否则会报错误，Linux下设置环境变量如下：<br>
export DISPLAY=:0.0<br>
jvisualvm同jconsole都是一个基于图形化界面的、可以查看本地及远程的JAVA GUI监控工具，Jvisualvm同jconsole的使用方式一样，直接在命令行打入Jvisualvm即可启动，不过Jvisualvm相比，界面更美观一些，数据更实时。</p>
<p>##、Jhat<br>
jhat用于对JAVA heap进行离线分析的工具，他可以对不同虚拟机中导出的heap信息文件进行分析，如LINUX上导出的文件可以拿到WINDOWS上进行分析，可以查找诸如内存方面的问题，不过jhat和MAT比较起来，就没有MAT那么直观了，MAT是以图形界面的方式展现结果。</p>
<!-- more -->
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Kafka 分析]]></title>
        <id>https://www.luoboyu.com/post/kafka-fen-xi</id>
        <link href="https://www.luoboyu.com/post/kafka-fen-xi">
        </link>
        <updated>2015-01-26T09:08:12.000Z</updated>
        <summary type="html"><![CDATA[<p>Kafka 作为一款基于磁盘存储的高吞吐消息中间件，常作为 log、event 等流式数据的通道，在流式计算领域也有丰富应用，下面简单分析其高吞吐、高性能的几点原因</p>
]]></summary>
        <content type="html"><![CDATA[<p>Kafka 作为一款基于磁盘存储的高吞吐消息中间件，常作为 log、event 等流式数据的通道，在流式计算领域也有丰富应用，下面简单分析其高吞吐、高性能的几点原因</p>
<!-- more -->
<h2 id="1-零拷贝">1、零拷贝</h2>
<p>普通的数据传输一般涉及 read、write 两个系统调用，而 kafka 的 broker 传递数据给消费者使用零拷贝的技术，底层使用了 sendfile 的系统调用，减少了用户态与内核态的上下文切换和数据拷贝的次数，read、write 两次系统调用涉及 4 次的上下文切换和 4 次的数据拷贝才能从一端到另一端，而 sendfile 系统调用只需要 2 次的上下文切换和 3 次的数据拷贝，减少了两次的上下文切换和一次拷贝动作，善用零拷贝可以优化基于磁盘的分布式系统的数据传输</p>
<h2 id="2-顺序写-page-cache">2、顺序写 + page cache</h2>
<p>普通磁盘的随机写性能较低，顺序写的性能则好很多，kafka 的存储模型就是一个 FIFO 的队列模型，不断地追加写文件，直到达到配置的大小限制（默认1GB）后进行翻滚，而当 kafka 的 partition 增多后，每个磁盘的随机写会增加，kafka 本身写入逻辑非常简单，使用普通的 java api，所以其完全依赖 linux 系统本身的 page cache，写到 page cache 后不是立刻写入磁盘，而要等待系统的 pdflush 线程进行刷盘操作，官方文档描述了 3 点使用 page cache 相对应用层缓存的优点：</p>
<ul>
<li>多次连续写入能批量汇聚成一次的物理写提高吞吐量</li>
<li>写入重排最小化磁头移动的次数，优化写入性能</li>
<li>自动使用系统的剩余内存</li>
</ul>
<h2 id="3-分区partition">3、分区（partition）</h2>
<p>partiton 是 topic 的子概念，一个 topic 可以分成多个 partition，partition 是 kafka 横向扩展和并行化的基础，每个 partition 都可以并行写入与读取，一般会预估数据的量级，选择合适的 partition 数量进行 topic 的创建，某种程度上而言，partition 越多意味着读写的吞吐量越大，当然不是绝对的，分区越多对于磁盘的顺序写影响越大，更容易产生随机写降低性能。关于分区基本上所有分布式（存储、计算）系统都有类似抽象，基本都是依托其作为水平扩展的基础</p>
<h2 id="4-reactor-网络模型">4、reactor 网络模型</h2>
<p>Kafka 的网络层使用 reactor 的线程模型，单个 acceptor 线程负责处理所有客户端的连接，建立连接后将 socket 的轮询分发给多个 processor 线程处理读写请求，processor 只负责数据的接收和发送，其后还有多个 handler 线程进行具体的逻辑操作，通过这样的异步线程模型，kafka 能够与成千上万的客户端交互而毫无压力</p>
]]></content>
    </entry>
</feed>